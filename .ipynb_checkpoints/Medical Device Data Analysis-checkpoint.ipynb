{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Work in Progress ***\n",
    "\n",
    "Pubmed Query Builder: https://pubmed.ncbi.nlm.nih.gov/advanced/\n",
    "\n",
    "### Notes\n",
    "* Dates stored in __repr___ format in JSON\n",
    "* 000 = Code for unobtainable PMUID\n",
    "\n",
    "### MeSH Terms\n",
    "* Biomedical Engineering \n",
    "* Biomedical Technology\n",
    "* Equipment Safety\n",
    "* Equipment Design\n",
    "* Prostheses and Implants\n",
    "\n",
    "### Querys\n",
    "((\"Equipment and Supplies\"[MeSH Terms] OR \"Equipment Design\"[MeSH Terms] OR \"Equipment Safety\"[MeSH Terms] OR \"Biomedical Technology\"[MeSH Terms] OR \"Biomedical Engineering\"[MeSH Terms]) AND 1850/01/01:1997/12/31[Date - Publication]) AND (English[Language])\n",
    "\n",
    "(((medical device[Title/Abstract]) OR (medical devices[Title/Abstract])) AND (english[Language])) AND ((\"1850\"[Date - Publication] : \"1997\"[Date - Publication]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a-5Jn7QOhBFO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "from pymed import PubMed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses Pymed to get results for the desired query\n",
    "def search(query_string, pubmed_module, max_results=2000):\n",
    "    results = pubmed_module.query(query_string, max_results=max_results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets relevant data from Pymed iterable and creates a dictionary\n",
    "def pubmed_todict(pubmed_iterable):\n",
    "    new_dict = {\"Result Number\": [], \"Pubmed ID\": [], \"Title\": [], \"Journal\": [], \"Authors\": [], \"Date\": []}\n",
    "    \n",
    "    # Assemble dictionary\n",
    "    for i, article in enumerate(pubmed_iterable):\n",
    "        new_dict[\"Result Number\"].append(i)\n",
    "        if \"\\n\" in article.pubmed_id:  # Deals with parsing issue for article PMUID\n",
    "            new_dict[\"Pubmed ID\"].append(\"000\")\n",
    "        else:\n",
    "            new_dict[\"Pubmed ID\"].append(article.pubmed_id)   \n",
    "        new_dict[\"Title\"].append(article.title)\n",
    "        try:  # Deals with book (rather than articles) in the database\n",
    "            new_dict[\"Journal\"].append(article.journal)\n",
    "        except AttributeError:\n",
    "            new_dict[\"Journal\"].append(\"Book\") \n",
    "        new_dict[\"Authors\"].append(article.authors)\n",
    "        new_dict[\"Date\"].append(article.publication_date)\n",
    "        \n",
    "    # Cleans author data\n",
    "    clean_author_list_by_paper = []\n",
    "    for paper_author_list in new_dict[\"Authors\"]:\n",
    "        if paper_author_list == []:\n",
    "            clean_author_list_by_paper.append([{\"name\": None, \"affiliation\": None}])\n",
    "        else:\n",
    "            author_list_by_paper = []\n",
    "            for author in paper_author_list:\n",
    "                if author[\"lastname\"] != None or author[\"initials\"] != None:\n",
    "                    try:\n",
    "                        author_dict = {\"name\": \"{} {}\".format(author[\"lastname\"], author[\"initials\"]),\n",
    "                                \"affiliation\": author[\"affiliation\"]}\n",
    "                    except KeyError:\n",
    "                        author_dict = {\"name\": \"{} {}\".format(author[\"lastname\"], author[\"initials\"]),\n",
    "                                    \"affiliation\": None}\n",
    "                    author_list_by_paper.append(author_dict)\n",
    "            clean_author_list_by_paper.append(author_list_by_paper)\n",
    "    \n",
    "    new_dict[\"Authors\"] = clean_author_list_by_paper\n",
    "    \n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoids serialization error with datetime in JSON dump\n",
    "# See https://stackoverflow.com/questions/54557568/typeerror-object-of-type-date-is-not-json-serializable\n",
    "def datetime_converter(object):\n",
    "    if isinstance(object, datetime.datetime):\n",
    "        return object.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_dump(query_string, max_results, file_name):\n",
    "    pubmed = PubMed(tool=\"Medical Device Author Network Analysis\", email=\"bowrey@umd.edu\")\n",
    "    results = search(query_string=query_string, pubmed_module=pubmed, max_results=max_results)\n",
    "    new_dict = pubmed_todict(pubmed_iterable=results)\n",
    "    with open(file_name, \"w\") as f:\n",
    "        # Default argument takes function that is called when JSON ecounters object it can't convert\n",
    "        json.dump(new_dict, f, indent=4, default=datetime_converter)\n",
    "        print(\"Search Completed. File dumped to JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Completed. File dumped to JSON\n"
     ]
    }
   ],
   "source": [
    "# Searches for all items with \"medical device(s)\" in the title or abstract\n",
    "search_and_dump(query_string='''(((medical device[Title/Abstract]) OR (medical devices[Title/Abstract])) AND (english[Language])) \n",
    "                                AND ((\"1850\"[Date - Publication] : \"1997\"[Date - Publication]))''',\n",
    "               max_results=2000, file_name=\"device_pubmed_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Anaylsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass Author:\\n    def __init__(self, ident, name, affiliation, weight):\\n        self.ident = ident\\n        self.name = name\\n        self.affiliation = affiliation\\n        self.weight = weight\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class Author:\n",
    "    def __init__(self, ident, name, affiliation, weight):\n",
    "        self.ident = ident\n",
    "        self.name = name\n",
    "        self.affiliation = affiliation\n",
    "        self.weight = weight\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_info(auth_list , write_file):\n",
    "    identifier_list = {}\n",
    "    id_count = 1\n",
    "    \n",
    "    for paper in auth_list:\n",
    "        for author in paper:\n",
    "            # Create data structure for author\n",
    "            if author[\"name\"] == None:\n",
    "                break\n",
    "            elif author[\"name\"].lower() in [item.lower() for item in identifier_list.keys()]:\n",
    "                identifier_list[author[\"name\"]][\"weight\"] += 1\n",
    "            else:\n",
    "                identifier_list[author[\"name\"]]  = {\"id\": id_count, \"affiliation\":author[\"affiliation\"], \"weight\": 1, \"edges\":[]}\n",
    "\n",
    "            # Append other authors to edges list\n",
    "            temp_list = [o_author[\"name\"] for o_author in paper]\n",
    "            for item in temp_list:\n",
    "                if item != author[\"name\"]:\n",
    "                    identifier_list[author[\"name\"]][\"edges\"].append(item) \n",
    "\n",
    "            id_count +=1\n",
    "            \n",
    "    with open(write_file, \"w\") as f:\n",
    "        json.dump(identifier_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"device_pubmed_data.json\", \"r\") as f:\n",
    "    auth_list = json.load(f)[\"Authors\"]\n",
    "    get_author_info(auth_list=auth_list , write_file=\"device_author_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994\n"
     ]
    }
   ],
   "source": [
    "with open(\"device_author_data.json\") as f:\n",
    "    test = json.load(f)\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "PubMed API Data Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
